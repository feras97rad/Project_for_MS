{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stir_not_shake(recipe, ingredients):\n",
    "  # Проверка, есть ли все ингредиенты\n",
    "  for ingredient, amount in recipe.items():\n",
    "    if ingredient not in ingredients or ingredients[ingredient] < amount:\n",
    "      return 0\n",
    "\n",
    "  # Определение количества коктейлей\n",
    "  min_amount = float('inf')\n",
    "  for ingredient, amount in recipe.items():\n",
    "    if ingredients[ingredient] / amount < min_amount:\n",
    "      min_amount = ingredients[ingredient] / amount\n",
    "\n",
    "  return int(min_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check (examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Иван может сделать 2 коктейлей.\n"
     ]
    }
   ],
   "source": [
    "num_cocktails = stir_not_shake(\n",
    "    {'bourbon': 50, 'vermouth': 25, 'angostura': 1, 'cherry': 1},\n",
    "    {'bourbon': 500, 'vermouth': 750, 'angostura': 150, 'cherry': 2, 'eggs': 20}\n",
    ")\n",
    "\n",
    "print(f\"Иван может сделать {num_cocktails} коктейлей.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Иван может сделать 0 коктейлей.\n"
     ]
    }
   ],
   "source": [
    "num_cocktails = stir_not_shake(\n",
    "    {'prosecco': 90, 'orange_juice': 90},\n",
    "    {'prosecco': 1500, 'campari': 750, 'vermouth': 750}\n",
    ")\n",
    "print(f\"Иван может сделать {num_cocktails} коктейлей.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Импорт необходимых библиотек\\nimport datetime    # Для работы с форматами даты и времени\\nimport pandas as pd     # Для работы с данными (предобработка, анализ)\\nimport clickhouse_driver    # Для подключения к СУБД ClickHouse\\nimport plotly.express as px     # Для визуализации\\nimport getpass      # Для логина в БД\\n\\n# Подключение к ClickHouse (ввод логина и пароля)\\nhost_name = f\\'{ваш_хост}\\'\\nuser_name = f\\'{ваше_имя_пользователя}\\'\\npassword = getpass.getpass(prompt=\\'Password: \\')\\ndb = f\\'{ваша_база_данных}\\'\\n\\n# Подключение к ClickHouse\\nch = clickhouse_driver.Client(host=host_name, user=user_name, password=password, database=db)\\n\\n# Объявление переменной и присвоение ей результата SQL-запроса\\nilp_query = \"\"\"\\nselect *\\nfrom geo_comp_list\\nwhere 1=1\\n    and dt = (select max(dt) from geo_comp_list) -- Получение данных только за последнюю дату\\n    and panel = \\'iLP\\'  -- Фильтрация по панели \\'iLP\\'\\n\"\"\"\\n\\n# Выполнение запроса и сохранение результатов в DataFrame\\ndf_ilp = ch.query_dataframe(ilp_query)\\n\\n# Загрузка данных из двух отдельных CSV-файлов\\ndf_pm = pd.read_csv(\\'geo-data/geo-pm.csv\\', sep=\\';\\')\\ndf_scp = pd.read_csv(\\'geo-data/geo-scp.csv\\', sep=\\';\\')\\n\\n# Объединение данных из разных источников в один DataFrame\\ndf = pd.concat([df_pm, df_scp, df_ilp], ignore_index=True)\\n\\n# Получение максимальной даты в данных\\ndt = df[\\'dt\\'].max()\\n\\n# Фильтрация данных: оставляются только записи с comparison == False\\nbr = df[df[\\'comparison\\'] == False]\\n\\n# Экспорт отфильтрованных данных в Excel-файл\\nfilename = f\\'C:\\\\Users\\\\Workwork\\\\Documents\\\\Panel\\\\{str(dt)}-bad-region.xlsx\\'\\nbr.to_excel(filename)\\n\\n# Присоединение данных о регионах из другого DataFrame (предполагается, что df_scp имеет столбцы georegionid, city_town_locality, district, state и federal_area)\\n# методом merge по столбцам \\'anc_id\\' и \\'georegionid\\'\\nbr_anc = br.merge(\\n    rh[[\\'georegionid\\',\\'city_town_locality\\', \\'district\\', \\'state\\', \\'federal_area\\']],\\n    left_on=\\'anc_id\\',\\n    right_on=\\'georegionid\\'\\n)\\n\\n# Группировка данных по столбцам и агрегация количества (count) уникальных логинов (login)\\ntree_anc = br_anc.groupby([\\'federal_area\\', \\'state\\', \\'recrout_type\\', \\'panel\\'])    .agg(cnt=(\\'login\\',\\'nunique\\')).reset_index()\\n\\n# Создание визуализации TreeMap с помощью Plotly Express\\nfig = px.treemap(\\n    tree_anc,\\n    path=[\\'federal_area\\', \\'recrout_type\\', \\'panel\\'],\\n    values=\\'cnt\\',\\n    title=\"Разница в географии, регионы из анкеты\"\\n)\\n\\n# Настройка внешнего вида визуализации\\nfig.data[0].textinfo = \\'label+text+value\\'\\nfig.layout.hovermode = False\\n\\n# Отображение визуализации\\nfig.show()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Импорт необходимых библиотек\n",
    "import datetime    # Для работы с форматами даты и времени\n",
    "import pandas as pd     # Для работы с данными (предобработка, анализ)\n",
    "import clickhouse_driver    # Для подключения к СУБД ClickHouse\n",
    "import plotly.express as px     # Для визуализации\n",
    "import getpass      # Для логина в БД\n",
    "\n",
    "# Подключение к ClickHouse (ввод логина и пароля)\n",
    "host_name = f'{ваш_хост}'\n",
    "user_name = f'{ваше_имя_пользователя}'\n",
    "password = getpass.getpass(prompt='Password: ')\n",
    "db = f'{ваша_база_данных}'\n",
    "\n",
    "# Подключение к ClickHouse\n",
    "ch = clickhouse_driver.Client(host=host_name, user=user_name, password=password, database=db)\n",
    "\n",
    "# Объявление переменной и присвоение ей результата SQL-запроса\n",
    "ilp_query = \"\"\"\n",
    "select *\n",
    "from geo_comp_list\n",
    "where 1=1\n",
    "    and dt = (select max(dt) from geo_comp_list) -- Получение данных только за последнюю дату\n",
    "    and panel = 'iLP'  -- Фильтрация по панели 'iLP'\n",
    "\"\"\"\n",
    "\n",
    "# Выполнение запроса и сохранение результатов в DataFrame\n",
    "df_ilp = ch.query_dataframe(ilp_query)\n",
    "\n",
    "# Загрузка данных из двух отдельных CSV-файлов\n",
    "df_pm = pd.read_csv('geo-data/geo-pm.csv', sep=';')\n",
    "df_scp = pd.read_csv('geo-data/geo-scp.csv', sep=';')\n",
    "\n",
    "# Объединение данных из разных источников в один DataFrame\n",
    "df = pd.concat([df_pm, df_scp, df_ilp], ignore_index=True)\n",
    "\n",
    "# Получение максимальной даты в данных\n",
    "dt = df['dt'].max()\n",
    "\n",
    "# Фильтрация данных: оставляются только записи с comparison == False\n",
    "br = df[df['comparison'] == False]\n",
    "\n",
    "# Экспорт отфильтрованных данных в Excel-файл\n",
    "filename = f'C:\\\\Users\\\\Workwork\\\\Documents\\\\Panel\\\\{str(dt)}-bad-region.xlsx'\n",
    "br.to_excel(filename)\n",
    "\n",
    "# Присоединение данных о регионах из другого DataFrame (предполагается, что df_scp имеет столбцы georegionid, city_town_locality, district, state и federal_area)\n",
    "# методом merge по столбцам 'anc_id' и 'georegionid'\n",
    "br_anc = br.merge(\n",
    "    rh[['georegionid','city_town_locality', 'district', 'state', 'federal_area']],\n",
    "    left_on='anc_id',\n",
    "    right_on='georegionid'\n",
    ")\n",
    "\n",
    "# Группировка данных по столбцам и агрегация количества (count) уникальных логинов (login)\n",
    "tree_anc = br_anc.groupby(['federal_area', 'state', 'recrout_type', 'panel'])\\\n",
    "    .agg(cnt=('login','nunique')).reset_index()\n",
    "\n",
    "# Создание визуализации TreeMap с помощью Plotly Express\n",
    "fig = px.treemap(\n",
    "    tree_anc,\n",
    "    path=['federal_area', 'recrout_type', 'panel'],\n",
    "    values='cnt',\n",
    "    title=\"Разница в географии, регионы из анкеты\"\n",
    ")\n",
    "\n",
    "# Настройка внешнего вида визуализации\n",
    "fig.data[0].textinfo = 'label+text+value'\n",
    "fig.layout.hovermode = False\n",
    "\n",
    "# Отображение визуализации\n",
    "fig.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот скрипт нужен для:\n",
    "- получения данных из БД ClickHouse\n",
    "- подгрузки двух CSV-файлов и объединения их с результатом запроса их CH\n",
    "- Фильтрации данных и экспорт в Excel\n",
    "- визуализации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Здесь происходит выполнение SQL запроса на основе данных из таблицы osnova_d и activity_d с использованием Apache Spark\n",
    "где для каждой записи из osnova_d вычисляются различные метрики, связанные с активностью участников исследования.\n",
    "\n",
    "-- Объявление переменной и присвоение ей результата запроса\n",
    "val osnova_d_activity = spark.sql (\"\"\"\n",
    "    SELECT \n",
    "        osnova_d.*,\n",
    "                                   \n",
    "        -- Рассчитываем стаж (Experience) как разницу в датах между полями Data и DateFrom.\n",
    "        DATEDIFF(Data, DateFrom) AS Experience,\n",
    "                                   \n",
    "        -- Рассчитываем количество активных участников за последние 30 дней как Active30.\n",
    "        MAX(CASE WHEN a.researchdate BETWEEN DATE_ADD(Data, -29) AND Data THEN a.SubjectID END) AS Active30,\n",
    "                                   \n",
    "        -- Рассчитываем количество активных участников за последние 30 дней, исключая системных как Active30_not_system.\n",
    "        MAX(CASE WHEN a.researchdate BETWEEN DATE_ADD(Data, -29) AND Data THEN a.SubjectID END) AS Active30_not_system,\n",
    "                                   \n",
    "        -- Рассчитываем количество активных участников в текущем дне как Active0\n",
    "        MAX(CASE WHEN a.researchdate = Data THEN a.SubjectID END) AS Active0,\n",
    "                                   \n",
    "        -- Рассчитываем количество активных участников в текущем дне, исключая системных как Active0_not_system\n",
    "        MAX(CASE WHEN a.researchdate = Data THEN a.SubjectID END) AS Active0_not_system,\n",
    "                                   \n",
    "        -- Рассчитываем количество дней, когда участник был активным за последние 30 дней как Active30_days_in_month,\n",
    "        -- группируя по участнику и месяцу.\n",
    "        COUNT(MAX(CASE WHEN a.researchdate BETWEEN DATE_ADD(Data, -29) AND Data THEN a.SubjectID END)) OVER (PARTITION BY osnova_d.SubjectID, Month) AS Active30_days_in_month,\n",
    "                                   \n",
    "        -- Рассчитываем процент активности (округляя) за последние 30 дней от общего числа дней в месяце как Month_activity30_percent,\n",
    "        -- группируя по участнику и месяцу.\n",
    "        ROUND(COUNT(MAX(CASE WHEN a.researchdate BETWEEN DATE_ADD(Data, -29) AND Data THEN a.SubjectID END)) OVER (PARTITION BY osnova_d.SubjectID, Month) / MAX(DAY(Data)) OVER (PARTITION BY Month), 2) AS Month_activity30_percent\n",
    "    \n",
    "    -- Таблица, из которой берем данные\n",
    "    FROM \n",
    "        osnova_d\n",
    "    \n",
    "    -- Присоединяем к ней др таблицу методом left join (к левой таблице присоединяем правую)\n",
    "    LEFT JOIN \n",
    "        activity_d a\n",
    "    \n",
    "    -- Определяем ключевой столбец по которому происходит объединение\n",
    "    ON \n",
    "        osnova_d.SubjectID = a.SubjectID\n",
    "\n",
    "    -- Группировка (выполняется последовательно слева направо)\n",
    "    GROUP BY \n",
    "        Data, osnova_d.Month, osnova_d.SubjectID, Panel, Recrout_type, Research_type, DateFrom, DateTo, In, Out\n",
    "\"\"\")\n",
    " Записываем результаты в файл \"osnova_d_activity\".\n",
    "osnova_d_activity.write.mode(\"overwrite\").parquet(Path.concat(\"osnova_d_activity\"))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот скрипт нужен для анализа активности участников исследования на основе данных из двух таблиц \"osnova_d\" и \"activity_d\". Он выполняет несколько расчетов и агрегаций, чтобы получить информацию о стаже участников, количестве активных участников за последние 30 дней, их дневной активности и другие метрики. Результаты анализа сохраняются в parquet-файл для дальнейшего анализа."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
